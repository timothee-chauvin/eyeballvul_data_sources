{
  "affected": [
    {
      "database_specific": {
        "source": "https://storage.googleapis.com/cve-osv-conversion/osv-output/CVE-2025-48942.json"
      },
      "ranges": [
        {
          "events": [
            {
              "introduced": "966f933ee1cd7c9a41db60de5c7ff98657005251"
            },
            {
              "fixed": "58738772410c5e0d60b61db39538a9b313d2d7ad"
            }
          ],
          "repo": "https://github.com/vllm-project/vllm",
          "type": "GIT"
        }
      ],
      "versions": []
    }
  ],
  "aliases": [
    "GHSA-6qc9-v4r8-22xg",
    "PYSEC-2025-54"
  ],
  "details": "vLLM is an inference and serving engine for large language models (LLMs). In versions 0.8.0 up to but excluding 0.9.0, hitting the  /v1/completions API with a invalid json_schema as a Guided Param kills the vllm server. This vulnerability is similar GHSA-9hcf-v7m4-6m2j/CVE-2025-48943, but for regex instead of a JSON schema. Version 0.9.0 fixes the issue.",
  "id": "CVE-2025-48942",
  "modified": "2025-10-14T14:34:40Z",
  "published": "2025-05-30T18:33:40Z",
  "references": [
    {
      "type": "ADVISORY",
      "url": "https://github.com/vllm-project/vllm/security/advisories/GHSA-6qc9-v4r8-22xg"
    },
    {
      "type": "FIX",
      "url": "https://github.com/vllm-project/vllm/commit/08bf7840780980c7568c573c70a6a8db94fd45ff"
    },
    {
      "type": "FIX",
      "url": "https://github.com/vllm-project/vllm/pull/17623"
    },
    {
      "type": "REPORT",
      "url": "https://github.com/vllm-project/vllm/issues/17248"
    }
  ],
  "related": [
    "CGA-6q3c-f3f5-gh6x"
  ],
  "schema_version": "1.7.3",
  "severity": [
    {
      "score": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H",
      "type": "CVSS_V3"
    }
  ],
  "summary": "vLLM DOS: Remotely kill vllm over http with invalid JSON schema"
}